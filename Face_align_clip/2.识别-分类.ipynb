{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Utilities库\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import facenet\n",
    "import detect_face\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin: Number of classes: 5750\n",
      "Origin: Number of images: 13233\n",
      "Filtered: Number of classes: 423\n",
      "Filtered: Number of images: 5985\n",
      "Loading feature extraction model\n",
      "Model filename: D:\\pythonworks\\01_erhwen\\real-time-deep-face-recognition\\model\\facenet\\20170512-110547\\20170512-110547.pb\n",
      "Face embedding size:  128\n",
      "Calculating features for images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:27<00:00,  4.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# 使用Tensorflow的Facenet模型\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        datadir = IMG_OUT_PATH  # 检测、对齐、裁剪后的图像目录\n",
    "        dataset = facenet.get_dataset(datadir)\n",
    "        paths, labels, labels_dict = facenet.get_image_paths_and_labels(\n",
    "            dataset)\n",
    "        print('Origin: Number of classes: %d' % len(labels_dict))\n",
    "        print('Origin: Number of images: %d' % len(paths))\n",
    "\n",
    "        # 由于lfw的人脸图像集中有很多的人脸类别只有1张的图像\n",
    "        # 所以只使用图像样本數大于5的人脸类别\n",
    "\n",
    "        paths, labels, labels_dict = facenet.get_image_paths_and_labels(\n",
    "            dataset, enable_filter=True, filter_size=5)\n",
    "        print('Filtered: Number of classes: %d' % len(labels_dict))\n",
    "        print('Filtered: Number of images: %d' % len(paths))\n",
    "\n",
    "        # 载入Facenet模型\n",
    "        print('Loading feature extraction model')\n",
    "        modeldir = FACENET_MODEL_PATH  #'/..Path to Pre-trained model../20170512-110547/20170512-110547.pb'\n",
    "        facenet.load_model(modeldir)\n",
    "\n",
    "        images_placeholder = tf.get_default_graph().get_tensor_by_name(\n",
    "            \"input:0\")\n",
    "        embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\n",
    "            \"phase_train:0\")\n",
    "        embedding_size = embeddings.get_shape()[1]\n",
    "        # 打印\"人脸特征\"的向量大小\n",
    "        print(\"Face embedding size: \", embedding_size)\n",
    "\n",
    "        # 计算人脸特征向量 (128 bytes)\n",
    "        print('Calculating features for images')\n",
    "        batch_size = 1000  # 批次量\n",
    "        image_size = 160  # 作为Facenet的图像输入的大小\n",
    "\n",
    "        nrof_images = len(paths)  # 处理人脸图像的总数\n",
    "        # 计算批次\n",
    "        nrof_batches_per_epoch = int(math.ceil(1.0 * nrof_images / batch_size))\n",
    "        # 构建一个变量保存人脸特征向量\n",
    "        emb_array = np.zeros(\n",
    "            (nrof_images, embedding_size))  # <-- Face Embedding\n",
    "\n",
    "        for i in tqdm(range(nrof_batches_per_epoch)):\n",
    "            start_index = i * batch_size\n",
    "            end_index = min((i + 1) * batch_size, nrof_images)\n",
    "            paths_batch = paths[start_index:end_index]\n",
    "            images = facenet.load_data(paths_batch, False, False, image_size)\n",
    "            feed_dict = {\n",
    "                images_placeholder: images,\n",
    "                phase_train_placeholder: False\n",
    "            }\n",
    "            emb_array[start_index:end_index, :] = sess.run(embeddings,\n",
    "                                                           feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#序列化可重复使用的数据\n",
    "\n",
    "# 保存人脸embedding的数据\n",
    "emb_features_file = open(os.path.join(DATA_PATH,'lfw_emb_features.pkl'), 'wb')\n",
    "pickle.dump(emb_array, emb_features_file)\n",
    "emb_features_file.close()\n",
    "\n",
    "# 保存人脸embedding所对应坐标(label)的数据\n",
    "emb_lables_file = open(os.path.join(DATA_PATH,'lfw_emb_labels.pkl'), 'wb')\n",
    "pickle.dump(labels, emb_lables_file)\n",
    "emb_lables_file.close()\n",
    "\n",
    "# 保存\"标签(label)对应到人脸的字典的数据\n",
    "emb_lables_dict_file = open(os.path.join(DATA_PATH,'lfw_emb_labels_dict.pkl'), 'wb')\n",
    "pickle.dump(labels_dict, emb_lables_dict_file)\n",
    "emb_lables_dict_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 反序列化可重复使用的数据\n",
    "\n",
    "# 人脸embedding的数据\n",
    "with open(os.path.join(DATA_PATH,'lfw_emb_features.pkl'), 'rb') as emb_features_file:\n",
    "    emb_features =pickle.load(emb_features_file)\n",
    "\n",
    "# 人脸embedding所对应的标签(label)的数据\n",
    "with open(os.path.join(DATA_PATH,'lfw_emb_labels.pkl'), 'rb') as emb_lables_file:\n",
    "    emb_labels =pickle.load(emb_lables_file)\n",
    "\n",
    "# 标签(label)对应到人脸名称的字典的数据\n",
    "with open(os.path.join(DATA_PATH,'lfw_emb_labels_dict.pkl'), 'rb') as emb_lables_dict_file:\n",
    "    emb_labels_dict =pickle.load(emb_lables_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人臉embedding featues: 5985, shape: (5985, 128), type: <class 'numpy.ndarray'>\n",
      "人臉embedding labels: 5985, type: <class 'list'>\n",
      "人臉embedding labels dict: {}, type: {} 423 <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(\"人臉embedding featues: {}, shape: {}, type: {}\".format(len(emb_features), emb_features.shape, type(emb_features)))\n",
    "print(\"人臉embedding labels: {}, type: {}\".format(len(emb_labels), type(emb_labels)))\n",
    "print(\"人臉embedding labels dict: {}, type: {}\", len(emb_labels_dict), type(emb_labels_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 5562, y_train: 5562\n",
      "X_test: 423, y_test: 423\n"
     ]
    }
   ],
   "source": [
    "# 相关变量\n",
    "X_train = []; y_train = []\n",
    "X_test = []; y_test = []\n",
    "\n",
    "# 保存已经处理的人脸label\n",
    "processed = set()\n",
    "\n",
    "# 分割训练数据集与验证数据集\n",
    "for (emb_feature, emb_label) in zip(emb_features, emb_labels):\n",
    "    if emb_label in processed:\n",
    "        X_train.append(emb_feature)\n",
    "        y_train.append(emb_label)\n",
    "    else:\n",
    "        X_test.append(emb_feature)\n",
    "        y_test.append(emb_label)\n",
    "        processed.add(emb_label)\n",
    "\n",
    "# 结果\n",
    "print('X_train: {}, y_train: {}'.format(len(X_train), len(y_train)))\n",
    "print('X_test: {}, y_test: {}'.format(len(X_test), len(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n",
      "Validation result:  0.978723404255\n"
     ]
    }
   ],
   "source": [
    "# 训练分类器\n",
    "print('Training classifier')\n",
    "linearsvc_classifier = LinearSVC(C=1, multi_class='ovr')\n",
    "\n",
    "# 进行训练\n",
    "linearsvc_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 使用验证集验证准确率\n",
    "score = linearsvc_classifier.score(X_test, y_test)\n",
    "\n",
    "# 打印准确率\n",
    "print(\"Validation result: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved classifier model to file \"D:\\pythonworks\\01_erhwen\\real-time-deep-face-recognition\\model\\svm\\lfw_svm_classifier.pkl\"\n"
     ]
    }
   ],
   "source": [
    "# 序列化人脸莫模型\n",
    "classifier_filename = SVM_MODEL_PATH\n",
    "\n",
    "# 产生一个人脸的人名列表，便于识别使用\n",
    "#class_names = [cls.name.replace('_', ' ') for cls in dataset]\n",
    "\n",
    "class_names = []\n",
    "for key in sorted(emb_labels_dict.keys()):\n",
    "    class_names.append(emb_labels_dict[key].replace('_', ' '))\n",
    "\n",
    "# 保存人脸分类器\n",
    "with open(classifier_filename, 'wb') as outfile:\n",
    "    pickle.dump((linearsvc_classifier, class_names), outfile)\n",
    "    \n",
    "print('Saved classifier model to file \"%s\"' % classifier_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
